<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
    <style>
        div.padded {
            padding-top: 0px;
            padding-right: 100px;
            padding-bottom: 0.25in;
            padding-left: 100px;
        }
    </style>
    <title>Chaomin Li, Zhiqi Yu  |  CS 184</title>
    <meta http-equiv="content-type" content="text/html; charset=utf-8" />
    <link rel="stylesheet" type="text/css" href="style.css" media="screen" />
    <link href="https://fonts.googleapis.com/css?family=Open+Sans|Source+Sans+Pro" rel="stylesheet" />

    <script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\\(', '\\)']]
            }
        };
    </script>
    <script id="MathJax-script" async=async
            src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js">
    </script>
</head>
<body>
    <br />
    <h1 align="middle">Assignment 3-2: Additional Features to PathTracer</h1>
    <h2 align="middle">Chaomin Li</h2>
    <h2 align="middle">Zhiqi Yan</h2>
    <h2 align="middle">Website URL: <a href="https://zhaominl.github.io/project-webpage-qq360/proj3-2/index.html">LINK</a></h2>

    <div class="padded">


        * NOTE: For this project, you will choose TWO out of the four given parts to complete. One of those parts must be Part 1 or Part 2. In other words, you can choose any combination of two parts except the pair (Part 3, Part 4).
        <h3>Parts to be graded: P2 and P4</h3>

        <h3 align="middle">Overview</h3>

        <p>
            <b>
                The path-tracing algorithm allows us to render realistic surface of scene objects via different technique. In part 2, we implemented the Microfacet model, making surface rendered more reasonable. In part 4, we implemented depth of field so that the focusing of scene can be adjusted to different distance.
            </b>
        </p>
        <br />


        <h3 align="middle">Part 2. Microfacet Material</h3>
        <p>
            <b>
                What we did?
            </b>
        </p>
        <p>
            In this part, we implemented the Microfacet model to simulate different types of conductor materials, specifically those isotropic rough conductors that only reflect.
            To decide how the microfacets' normals are distributed, we implement the normal distribution function (NDF) with Beckmann distribution. With material roughness, we can
            compute the NDF at half vector h. We also calculate the wavelength-dependent Fresnel term for air-conductor. We look for specific \(\eta\) and \(k\) values for one material,
            plugging them into the formula to calculate the Fresnel term. With these and the shadowing-masking term, we can realize the BRDF evaluation function for this Microfacet
            model. Finally, we re-write the sampling function to implement importance sampling, calculating the actual pdf \(p_\omega(w_i)\) for the sample rays in this Microfacet model.
        </p>
        <p>
            <b>
                Show a screenshot sequence of 4 images of scene `CBdragon_microfacet_au.dae` rendered with $\alpha$ set to 0.005, 0.05, 0.25 and 0.5. The other settings should be at
                least 128 samples per pixel and 1 samples per light. The number of bounces should be at least 5. Describe the differences between different images. Note that, to change
                the $\alpha$, just open the .dae file and search for `microfacet`.
            </b>
        </p>
        <p>
            The variable \(\alpha\) is the roughness of the macro surface, and this value significantly affects how picture is rendered in Microfacet model. The smaller
            \(\alpha\) is, the smoother the macro surface will be. Visually, we see the material looks more diffuse with large \(\alpha\), and looks more glossy with small \(\alpha\).
            Here, we rendered four dragon picture with \(\alpha\)s equal to 0.005, 0.05, 0.25, and 0.5. <br />
            By comparing the pictures below, we see that with large \(\alpha\) (0.5), the dragon looks diffuse. The surfuce looks rough and does not reflect its environmental details.
            This is because the microfacets are uneven and reflecting lights to many different directions. Contrast to the large \(\alpha\), dragon with a small \(\alpha\) (0.005) appears
            to be more glossy and mirror-like, and the environmental details are reflected on the statue's surface. This is because, with a small \(\alpha\), the macro surface becomes
            smoother, and the microfacets are more aligned together. However, as we see in picture, a small \(\alpha\) might cause more noise (white dots) when rendering.
        </p>
        <div align="middle">
            <table style="width:100%">
                <tr align="center">
                    <td>
                        <img src="img/CBdragon_a0005.png" align="middle" width="400px" />
                        <figcaption>Render with 0.005 Roughness Dragon Statue(CBdragon_microfacet_au.dae)</figcaption>
                    </td>
                    <td>
                        <img src="img/CBdragon_a005.png" align="middle" width="400px" />
                        <figcaption>Render with 0.05 Roughness Dragon Statue(CBdragon_microfacet_au.dae)</figcaption>
                    </td>
                </tr>
                <tr align="center">
                    <td>
                        <img src="img/CBdragon_a025.png" align="middle" width="400px" />
                        <figcaption>Render with 0.25 Roughness Dragon Statue(CBdragon_microfacet_au.dae)</figcaption>
                    </td>
                    <td>
                        <img src="img/CBdragon_a05.png" align="middle" width="400px" />
                        <figcaption>Render with 0.5 Roughness Dragon Statue(CBdragon_microfacet_au.dae)</figcaption>
                    </td>
                </tr>
            </table>
        </div>
        <br />
        <p>
            <b>
                Show two images of scene `CBbunny_microfacet_cu.dae` rendered using cosine hemisphere sampling (default) and your importance sampling. The sampling rate should be
                fixed at 64 samples per pixel and 1 samples per light. The number of bounces should be at least 5. Briefly discuss their difference.
            </b>
        </p>
        <div align="middle">
            <table style="width:100%">
                <tr align="center">
                    <td>
                        <img src="img/CBbunny_coshemi.png" align="middle" width="400px" />
                        <figcaption>Rendering CBbunny_microfacet_cu with Cosine Hemisphere Sampling</figcaption>
                    </td>
                    <td>
                        <img src="img/CBbunny_beckmann.png" align="middle" width="400px" />
                        <figcaption>Rendering CBbunny_microfacet_cu with Microfacet Importance Sampling</figcaption>
                    </td>
                </tr>
            </table>
        </div>
        <p>
            Comparing two pictures, we find the bunny rendered on the left has more black dots and white noise than the bunny on the right. The right bunny, which is rendered
            with importance sampling the microfacet BRDF, looks more natural and copper-like. This is because, in importance sampling, we calculate the \(p_\theta\) and \(p_\phi\) to
            resemble the \(D(h)\) (NDF with Beckmann distribution at half vector h). Acoording to the importance sampling theory, the more these pdfs resemble the NDF on h, the less
            noise we will see. With Cosine hemisphere sampling, we sample the rays based on the cos pdf on the hemisphere, and this pdf does not match with the NDF we used on our microfacet,
            which is the Beckmann distribution. As we assume the specular of the surface, the cos-hemishpere sample rays mismatch with the actual reflection rays on the microfacets.
            Therefore, we see many black spots on the rabbit. For importance sampling with NDF (Beckmann), we calculate the \(p_\omega(w_i)\) based on the microfacet and its roughness, also the
            half vector h using \(\theta, \phi\). Hence, we better incorporate the microfacet's feature and generate a better picture.
        </p>
        <br />
        <p>
            <b>
                Show at least one image with some other conductor material, replacing `eta` and `k`. Note that you should look up values for real data rather than modifying them
                arbitrarily. Tell us what kind of material your parameters correspond to.
            </b>
        </p>
        <p>
            Refering to <a href="https://refractiveindex.info/">this website</a>, we set the wavelength to 614 nm (red), 549 nm (green) and 466 nm (blue). And we find the <br />
            \(\eta = 2.8851 | 2.9500 | 2.6500\)<br /> \(k = 3.0449 | 2.9300 | 2.8075 \) <br />
            for <b>Iron</b> material. We update the microfacet in <i>CBdragon_microfacet_au.dae</i> and <i>CBbunny_microfacet_cu.dae</i> with new value of eta and k. And we get following pictures
            showing the bunny and dragon statues with iron surface:
        </p>
        <div align="middle">
            <table style="width:100%">
                <tr align="center">
                    <td>
                        <img src="img/CBdragon_microfacet_fe.png" align="middle" width="400px" />
                        <figcaption>Apply Iron Material to Dragon Statue(CBdragon_microfacet.dae)</figcaption>
                    </td>
                    <td>
                        <img src="img/CBbunny_fe.png" align="middle" width="400px" />
                        <figcaption>Apply Iron Material to Bunny Statue(CBbunny_microfacet.dae)</figcaption>
                    </td>
                </tr>
            </table>
        </div>
        <br />


        <h3 align="middle">Part 4. Depth of Field</h3>
        <b>
            For these subparts, we recommend using a microfacet BSDF scene to show off the cool out of focus effects you can get with depth of field!
        </b>
        <p>
            <b>
                In a few sentences, explain the differences between a pinhole camera model and a thin-lens camera model.
            </b>
        </p>
        <p>
            The thin-lens camera model simulate real human-eye effect that only objects on plane of focus are focused and clear to see while other places
            in the scene is out of focus. \n
            Unlike pinhole camera, Location on the image plane in thin-lens model takes radiance from rays going from not
            only the center of lens but also other places on the len that has rays refracted to the same location on the image plane.
            If we trace back that refracted ray back to the scene, we will find it intersecting the ray that originates from the same location on the image plane
            and goes through center of the len at the plane of focus, which is focal distance away from the len. \n
            We generate that refracted ray by uniformly sample the len disk to the scenes and do ray tracing stuff that we have done in project 3-1
            will give us the depth of field effect.
            
        </p>
        <br />
        <p>
            <b>
                Show a "focus stack" where you focus at 4 visibly different depths through a scene. Make sure to include all screenshots.
            </b>
        </p>
        <p>
            We rendered "CBbunny_microfacet_cu.dae" using 4 different focal distance, while using 256 samples per pixel, 4 samples per light, max ray depth of 12,
            and lens radius of 0.05 . We can gradually see clearly the head, ears, and body of the bunny as we increase the focal distance.
        </p>
        <div align="middle">
            <table style="width:100%">
                <tr align="center">
                    <td>
                        <img src="img/bunny_d_1_2.png" align="middle" width="400px" />
                        <figcaption>Render with focal distance of 1.2 (CBbunny_microfacet_cu.dae)</figcaption>
                    </td>
                    <td>
                        <img src="img/bunny_d_1_4.png" align="middle" width="400px" />
                        <figcaption>Render with focal distance of 1.4 (CBbunny_microfacet_cu.dae)</figcaption>
                    </td>
                </tr>
                <tr align="center">
                    <td>
                        <img src="img/bunny_d_1_6.png" align="middle" width="400px" />
                        <figcaption>Render with focal distance of 1.6 (CBbunny_microfacet_cu.dae)</figcaption>
                    </td>
                    <td>
                        <img src="img/bunny_d_1_8.png" align="middle" width="400px" />
                        <figcaption>Render with focal distance of 1.8 (CBbunny_microfacet_cu.dae)</figcaption>
                    </td>
                </tr>
            </table>
        </div>
        <br />
        <p>
            <b>
                Show a sequence of 4 pictures with visibly different aperture sizes, all focused at the same point in a scene. Make sure to include all screenshots.
            </b>
        </p>
        <p>
            We rendered "CBbunny_microfacet_cu.dae" using 4 different lens radius, while using 256 samples per pixel, 4 samples per light, max ray depth of 12,
            and focal distance of 1.4 . We can see as lens radius goes up, locations other than center of the image becomes harder to see clearly.
        </p>
        <div align="middle">
            <table style="width:100%">
                <tr align="center">
                    <td>
                        <img src="img/bunny_b_005.png" align="middle" width="400px" />
                        <figcaption>Render with lens radius of 0.05 (CBbunny_microfacet_cu.dae)</figcaption>
                    </td>
                    <td>
                        <img src="img/bunny_b_010.png" align="middle" width="400px" />
                        <figcaption>Render with lens radius of 0.1 (CBbunny_microfacet_cu.dae)</figcaption>
                    </td>
                </tr>
                <tr align="center">
                    <td>
                        <img src="img/bunny_b_020.png" align="middle" width="400px" />
                        <figcaption>Render with lens radius of 0.2 (CBbunny_microfacet_cu.dae)</figcaption>
                    </td>
                    <td>
                        <img src="img/bunny_b_030.png" align="middle" width="400px" />
                        <figcaption>Render with lens radius of 0.3 (CBbunny_microfacet_cu.dae)</figcaption>
                    </td>
                </tr>
            </table>
        </div>
        <br />

        <h3 align="middle">Contribution</h3>
        <p>
            Our team includes Zhiqi Yan and Chaomin Li. Each person came up with his
            implementations for Part 1. In addition, Chaomin did part 2, and Zhiqi did part 4. And we together did the code review and optimization. The final version includes the code from both of us.
            For the report, Zhiqi wrote the Overview and Part4, and Chaomin wrote Part 2 and contribution. We contributed equally to the project report.
            During the whole homework, we work together, learn from the each other, and discuss our implementation of different parts in this homework.
        </p>

    </div>
</body>
</html>

